# Simple LLM Gateway Configuration

# Cost Limiting
COST_LIMIT_ENABLED=true
COST_LIMIT_PER_TASK=0.1

# LLM Provider API Keys
OPENAI_API_KEY=your_openai_api_key_here
CHUTES_API_KEY=your_chutes_api_key_here

# Gateway admin token (required to call /set-allowed-task-ids and /usage/*)
SANDBOX_GATEWAY_ADMIN_TOKEN=change_me

# Optional restrictions (recommended for security/cost control)
# Comma-separated lists. If empty: allow all.
# Example: OPENAI_ALLOWED_MODELS=gpt-5-mini,gpt-5.1
OPENAI_ALLOWED_MODELS=
CHUTES_ALLOWED_MODELS=

# OpenAI-compatible endpoints that miners may call through the gateway.
# Defaults to: /v1/chat/completions,/v1/responses
OPENAI_ALLOWED_PATHS=
CHUTES_ALLOWED_PATHS=

# If true: reject unknown model pricing instead of using fallback prices.
GATEWAY_STRICT_PRICING=true

# Chutes pricing refresh (seconds)
CHUTES_PRICING_TTL_SECONDS=3600
CHUTES_PRICING_TIMEOUT_SECONDS=10
