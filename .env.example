# LLM Configuration
LLM_PROVIDER="local" # 'local' or 'openai'
LOCAL_MODEL_ENDPOINT="http://localhost:6000/generate"

OPENAI_API_KEY="" #If LLM_PROVIDER='openai'

#Demo Webs Enpoint 
DEMO_WEBS_ENDPOINT="http://localhost"
DEMO_WEBS_STARTING_PORT=8000

# OpenAI Configuration
OPENAI_MODEL="gpt-4o-mini"
OPENAI_MAX_TOKENS="15000"
OPENAI_TEMPERATURE="0.7"

# Miner Web Agent Configuration
AGENT_NAME="<agent name>"
AGENT_HOST="localhost"
AGENT_PORT="8080"
USE_APIFIED_AGENT="false" # If you deploy your Agent set this value to true

# Evaluation
EVALUATOR_HEADLESS="true"

# Cache
SAVE_SUCCESSFULL_TASK_IN_JSON="false"